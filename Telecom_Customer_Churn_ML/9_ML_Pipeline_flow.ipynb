{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecccfbf7-12c1-44df-89ac-07a59e93b46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Cell 1 ‚Äî Load Train and Test Data\n",
    "# -------------------------------------------------------\n",
    "\n",
    "train_df = spark.table(\"kusha_solutions.telecom_churn_ml.train_final_featured_transformed\")\n",
    "test_df  = spark.table(\"kusha_solutions.telecom_churn_ml.test_final_featured_transformed\")\n",
    "\n",
    "print(\"‚úÖ Train and Test data loaded successfully.\")\n",
    "train_df.printSchema()\n",
    "test_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed855dc9-b8e3-416e-99c4-9ea7a135d7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#CELL 2 ‚Äî Convert Spark train_df ‚Üí pandas (flatten features)\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# -----------------------------\n",
    "# Convert train_df\n",
    "# -----------------------------\n",
    "train_flat = train_df.withColumn(\"features_arr\", vector_to_array(\"features_scaled\"))\n",
    "\n",
    "first_train = train_flat.select(\"features_arr\").head()\n",
    "n_features = len(first_train[\"features_arr\"])\n",
    "feature_cols = [f\"f{i}\" for i in range(n_features)]\n",
    "\n",
    "train_flat = train_flat.select(\n",
    "    *[F.col(\"features_arr\")[i].alias(f\"f{i}\") for i in range(n_features)],\n",
    "    F.col(\"Churn_index\").alias(\"label\")\n",
    ")\n",
    "\n",
    "pdf_train = train_flat.toPandas()\n",
    "print(\"Train pandas shape:\", pdf_train.shape)\n",
    "\n",
    "X_train = pdf_train[feature_cols]\n",
    "y_train = pdf_train[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a966c465-c6b1-4def-9326-8f2e5f7445dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#CELL 3 ‚Äî Convert Spark test_df ‚Üí pandas (same features)\n",
    "# -----------------------------\n",
    "# Convert test_df \n",
    "# ----------------------------- \n",
    "test_flat = test_df.withColumn(\"features_arr\", vector_to_array(\"features_scaled\"))\n",
    "\n",
    "test_flat = test_flat.select(\n",
    "    *[F.col(\"features_arr\")[i].alias(f\"f{i}\") for i in range(n_features)],\n",
    "    F.col(\"Churn_index\").alias(\"label\")\n",
    ")\n",
    "\n",
    "pdf_test = test_flat.toPandas()\n",
    "\n",
    "print(\"Test pandas shape:\", pdf_test.shape)\n",
    "\n",
    "X_test = pdf_test[feature_cols]\n",
    "y_test = pdf_test[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c33fc3-61d4-4d68-a502-ffa831be9986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# CELL 4 ‚Äî Train PURE PYTHON SKLEARN MODEL (FAST VERSION)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# üöÄ Optimized RF model (fast training, similar accuracy)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=120,        # ‚Üì faster, accuracy same\n",
    "    max_depth=10,           # ‚Üì faster, avoids overfitting\n",
    "    min_samples_split=5,    # ‚Üë better generalization\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Training sklearn RandomForest (optimized)...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"üéâ Pure Python sklearn RandomForest trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7430eb0-72a9-438a-a508-f577620c6cf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#CELL 5 ‚Äî Evaluate sklearn model on EXACT SAME Spark test_df\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "acc  = accuracy_score(y_test, preds)\n",
    "f1   = f1_score(y_test, preds, average=\"weighted\")\n",
    "prec = precision_score(y_test, preds, average=\"weighted\")\n",
    "rec  = recall_score(y_test, preds, average=\"weighted\")\n",
    "cm   = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"üìä sklearn model performance (using Spark test_df)\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"F1 Score :\", f1)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "\n",
    "class_labels = sorted(y_test.unique())\n",
    "df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(df_cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78804335-ae50-4c4d-9e26-1fc3fe1d00e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6 ‚Äî Create new experiment + log & register sklearn model\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Create a NEW experiment\n",
    "# -------------------------------------------------------\n",
    "mlflow.set_experiment(\"/Shared/telecom_churn_pure_python_exp\")\n",
    "\n",
    "print(\"üìå New experiment set: /Shared/telecom_churn_pure_python_exp\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Create signature + input example\n",
    "# -------------------------------------------------------\n",
    "input_example = X_train.head(5)\n",
    "signature = infer_signature(X_train, rf_model.predict(X_train))\n",
    "\n",
    "model_name = \"Churn_PurePython_Model_Final\"\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Start MLflow run and log + register model\n",
    "# -------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"Churn_PurePython_Run_Final\") as run:\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 300)\n",
    "    mlflow.log_param(\"max_depth\", 12)\n",
    "\n",
    "    # Log + register pure Python model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "print(\"üî• Model logged successfully!\")\n",
    "print(\"üÜî Run ID:\", run_id)\n",
    "print(\"üì¶ Model registered as:\", model_name)\n",
    "print(\"üëâ Use this model URI for loading: runs:/{}/model\".format(run_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ffeae89-1403-4e25-853a-93053eeddaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose X_train is your training DataFrame\n",
    "input_example = X_train.head(5)  # 5 sample rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d5fb61-7aad-4b16-be3c-136bde4f8002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded = mlflow.sklearn.load_model(\"runs:/5ffd86a2eeb34968ba610d13e9250f3b/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8576606a-a3a6-48df-a0df-b5bde8af008e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CELL 10 ‚Äî Load the logged sklearn model (pure Python) and test locally\n",
    "import mlflow\n",
    "\n",
    "loaded = mlflow.sklearn.load_model(\"runs:/5ffd86a2eeb34968ba610d13e9250f3b/model\")\n",
    "print(\"Loaded model:\", loaded)\n",
    "\n",
    "sample_preds = loaded.predict(input_example)\n",
    "print(\"Sample predictions:\", sample_preds)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9_ML_Pipeline_flow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
